{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a541c78-8b12-4d44-88b4-d8cfe61b9598",
   "metadata": {},
   "source": [
    "# NBA Game Prediction (1) - Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bfe06d-da59-41e1-a971-a17426919d98",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this script, we are scraping NBA data for our project to predict the outcome of NBA games. This script focuses on data collection, specifically on gathering NBA season standings and game scores from the basketball-reference.com website. We use the async_playwright package to interact with the website and BeautifulSoup to parse the HTML content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3693200-31d5-4b5a-9905-930e72a285b7",
   "metadata": {},
   "source": [
    "## Importing Libraries\n",
    "\n",
    "We import the necessary libraries. os is used for interacting with the operating system, BeautifulSoup is used for parsing HTML content, async_playwright is used for automating browser tasks, and time is used for time-related tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f13f733-b822-4655-b149-dc3fa3d79c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeout\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fc976b2e-62e2-4275-b65b-00fa1212c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install beautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13d94b4f-7cea-4f4e-b3b1-cf6c54570d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install playwright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1e4ec98e-80be-4520-bd45-5912bf2e976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !playwright install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33d3dc0-4386-46f1-a466-b97db8704930",
   "metadata": {},
   "source": [
    "## Defining Constants and Variables\n",
    "\n",
    "Here, we define some constants and variables. SEASONS is a list of the seasons we are interested in, and DATA_DIR, STANDINGS_DIR, and SCORES_DIR are the directories where we'll store our scraped data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51e090fc-617d-4058-8659-e045cc72762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEASONS = list(range(2016, 2023))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "61e49558-ea24-44f4-b788-dc202fa0abad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = \"NBA Game Prediction/data\"\n",
    "DATA_DIR = \"data\"\n",
    "STANDINGS_DIR = os.path.join(DATA_DIR, \"standings\")\n",
    "SCORES_DIR = os.path.join(DATA_DIR, \"scores\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5677de9b-1d8e-455e-8b2b-aa4ccafe2efb",
   "metadata": {},
   "source": [
    "## Defining the get_html Function\n",
    "This function is used to fetch the HTML content of a web page. It takes in a URL and a CSS selector to target specific parts of the web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec93da2e-98c6-4fbc-9515-5d902350989f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_html(url, selector, sleep=5, retries=3):\n",
    "    html = None\n",
    "    for i in range(1, retries+1):\n",
    "        time.sleep(sleep * i)\n",
    "        \n",
    "        try:\n",
    "            async with async_playwright() as p:\n",
    "                # browser = await p.chromium.launch()\n",
    "                browser = await p.firefox.launch()  #use firefox instead of chrome if there is timeout error with code \"html = await get_html(url, \"#content .filter\")\"\n",
    "                page = await browser.new_page()\n",
    "                await page.goto(url)\n",
    "                print(await page.title())\n",
    "                html = await page.inner_html(selector)\n",
    "        except PlaywrightTimeout:\n",
    "            print(f\"Timeout error on {url}\")\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "    return html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0419f2-6455-4065-ad52-1ee8ed513cc0",
   "metadata": {},
   "source": [
    "## Defining the scrape_season Function\n",
    "This function scrapes the season standings for a specific season. It saves the scraped HTML content to the standings directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbda61b1-1b22-4794-bad9-97e956487664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='seasons_scraping.log', level=logging.INFO)\n",
    "\n",
    "async def scrape_season(season):\n",
    "    url = f\"https://www.basketball-reference.com/leagues/NBA_{season}_games.html\"\n",
    "    html = await get_html(url, \"#content .filter\")\n",
    "\n",
    "    soup = BeautifulSoup(html)\n",
    "    links = soup.find_all(\"a\")\n",
    "    href = [l[\"href\"] for l in links]\n",
    "    standings_pages = [f\"https://basketball-reference.com{l}\" for l in href]\n",
    "\n",
    "    for url in tqdm(standings_pages, desc=f'Scraping season {season}'):\n",
    "        save_path = os.path.join(STANDINGS_DIR, url.split(\"/\")[-1])\n",
    "        if os.path.exists(save_path):\n",
    "            continue\n",
    "\n",
    "        html = await get_html(url, \"#all_schedule\")\n",
    "        if not html:\n",
    "            continue\n",
    "        with open(save_path, \"w+\") as f:\n",
    "            f.write(html)\n",
    "        \n",
    "        # Log the successful scrape\n",
    "        logging.info(f'Successfully scraped {url}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227f5475-1f5b-403a-8139-5839e37e677d",
   "metadata": {},
   "source": [
    "## Scraping Season Standings\n",
    "Here, we loop over each season in SEASONS and scrape the season standings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619d5c23-322b-4bd5-ac0e-241e2b6959d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to execute scraping seasons\n",
    "for season in SEASONS:\n",
    "    await scrape_season(season)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "55ce6ae9-5397-4f5a-9752-baa8aa35c55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/ruijiezheng/DS Project/NBA Game Prediction\n"
     ]
    }
   ],
   "source": [
    "# print current working directory for the noteboook\n",
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb12702-5959-4b7d-aa96-a0ada10f6362",
   "metadata": {},
   "source": [
    "## Getting the List of Standings Files\n",
    "We get a list of the standings files we've saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "479f369d-5224-442f-8f16-8244cce7a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "standings_files = os.listdir(STANDINGS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0717bf6b-8d7a-49b5-813c-68a22ec99f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NBA_2022_games-october.html',\n",
       " 'NBA_2021_games-june.html',\n",
       " 'NBA_2020_games-march.html',\n",
       " 'NBA_2020_games-september.html',\n",
       " 'NBA_2020_games-january.html',\n",
       " 'NBA_2020_games-august.html',\n",
       " 'NBA_2019_games-april.html',\n",
       " 'NBA_2022_games-may.html',\n",
       " 'NBA_2019_games-february.html',\n",
       " 'NBA_2018_games-february.html',\n",
       " 'NBA_2016_games-april.html',\n",
       " 'NBA_2021_games-march.html',\n",
       " 'NBA_2018_games-january.html',\n",
       " 'NBA_2017_games-february.html',\n",
       " 'NBA_2016_games-february.html',\n",
       " 'NBA_2017_games-october.html',\n",
       " 'NBA_2018_games-april.html',\n",
       " 'NBA_2020_games-december.html',\n",
       " 'NBA_2019_games-october.html',\n",
       " 'NBA_2020_games-november.html',\n",
       " 'NBA_2021_games-may.html',\n",
       " 'NBA_2021_games-december.html',\n",
       " 'NBA_2022_games-april.html',\n",
       " 'NBA_2020_games-october-2019.html',\n",
       " 'NBA_2022_games-december.html',\n",
       " 'NBA_2017_games-april.html',\n",
       " 'NBA_2022_games-november.html',\n",
       " 'NBA_2016_games-january.html',\n",
       " 'NBA_2018_games-october.html',\n",
       " 'NBA_2017_games-march.html',\n",
       " 'NBA_2021_games-february.html',\n",
       " 'NBA_2020_games-february.html',\n",
       " 'NBA_2017_games-june.html',\n",
       " 'NBA_2022_games-march.html',\n",
       " 'NBA_2018_games-june.html',\n",
       " 'NBA_2017_games-january.html',\n",
       " 'NBA_2020_games-october-2020.html',\n",
       " 'NBA_2022_games-february.html',\n",
       " 'NBA_2017_games-november.html',\n",
       " 'NBA_2016_games-december.html',\n",
       " 'NBA_2021_games-july.html',\n",
       " 'NBA_2016_games-november.html',\n",
       " 'NBA_2022_games-june.html',\n",
       " 'NBA_2018_games-march.html',\n",
       " 'NBA_2017_games-december.html',\n",
       " 'NBA_2019_games-january.html',\n",
       " 'NBA_2016_games-october.html',\n",
       " 'NBA_2021_games-april.html',\n",
       " 'NBA_2019_games-november.html',\n",
       " 'NBA_2020_games-july.html',\n",
       " 'NBA_2018_games-december.html',\n",
       " 'NBA_2022_games-january.html',\n",
       " 'NBA_2018_games-november.html',\n",
       " 'NBA_2016_games-march.html',\n",
       " 'NBA_2019_games-december.html',\n",
       " 'NBA_2019_games-may.html',\n",
       " 'NBA_2016_games-may.html',\n",
       " 'NBA_2019_games-march.html',\n",
       " 'NBA_2017_games-may.html',\n",
       " 'NBA_2016_games-june.html',\n",
       " 'NBA_2019_games-june.html',\n",
       " 'NBA_2018_games-may.html',\n",
       " 'NBA_2021_games-january.html']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standings_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b503e236-e51a-4ae4-b57e-64351c903a98",
   "metadata": {},
   "source": [
    "## Defining the scrape_game Function\n",
    "This function scrapes the box score for each game in a season. It saves the scraped HTML content to the scores directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23ebc745-f865-4315-8123-4d9b0223c773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(filename='scores_scraping.log', level=logging.INFO)\n",
    "\n",
    "async def scrape_game(standings_file):\n",
    "\n",
    "    with open(standings_file, 'r') as f:\n",
    "        html = f.read()\n",
    "\n",
    "    soup = BeautifulSoup(html)\n",
    "    links = soup.find_all(\"a\")\n",
    "    hrefs = [l.get(\"href\") for l in links]\n",
    "    box_scores = [l for l in hrefs if l and \"boxscore\" in l and \".html\" in l]\n",
    "    box_scores = [f\"https://www.basketball-reference.com{l}\" for l in box_scores]  # give us full links of the box scores\n",
    "\n",
    "    for url in tqdm(box_scores, desc='Scraping games'):\n",
    "        save_path = os.path.join(SCORES_DIR, url.split(\"/\")[-1])\n",
    "        if os.path.exists(save_path):\n",
    "            continue\n",
    "\n",
    "        html = await get_html(url, \"#content\")\n",
    "        if not html:\n",
    "            continue\n",
    "        with open (save_path, \"w+\") as f:\n",
    "            f.write(html)\n",
    "\n",
    "        # Log the successful scrape\n",
    "        logging.info(f'Successfully scraped {url}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d1e667a8-ac98-4806-8cab-be2f759e6568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out any werid file\n",
    "standings_files = [s for s in standings_file if \".html\" in s]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede70aa6-43a9-4f22-b937-0229d7ad4839",
   "metadata": {},
   "source": [
    "## Scraping Box Scores\n",
    "Here, we loop over each file in standings_files and scrape the box scores for each game in the corresponding season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "670010bb-d713-47ef-a85d-dfb98a0e6f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to execute scraping box_score\n",
    "for f in standings_files:\n",
    "    filepath = os.path.join(STANDINGS_DIR, f)\n",
    "    \n",
    "    await scrape_game(filepath)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc2cb9c-8fe7-4680-a889-3700d936e2af",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This script successfully scrapes NBA season standings and game scores from the basketball-reference.com website. The scraped data is saved to the standings and scores directories, respectively. This data will be used in the next step of our project, where we'll parse the HTML content and transform it into a structured format for further analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
